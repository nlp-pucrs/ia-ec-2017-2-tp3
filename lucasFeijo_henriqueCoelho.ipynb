{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Olivetti Faces\n",
    "Nosso dataset é composto de 10 fotos de rostos de 40 diferentes pessoas, totalizando 400 imagens de 64x64 píxeis cada.\n",
    "\n",
    "### Topologia da Rede Neural\n",
    "A camada de input é composta por 4096 nodos, onde são injetados os píxeis da imagem de entrada.\n",
    "A camada de output é composta por 40 nodos, indicando a probabilidade de combinação com o rosto de uma determinada pessoa dentre as 40.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = fetch_olivetti_faces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = faces.data\n",
    "target = faces.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o dataset escolhido não há necessidade de pré-processamento, as imagens já são recebidas do mesmo tamanho, no mesmo formato, e em escala de cinza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validação Cruzada\n",
    "Para que seja feita validação cruzada, precisamos seccionar nosso dataset em dois pedaços: um para treinamento da rede e outro para avaliação do treinamento. Utilizando um método do SciKit chamado `train_test_split` conseguimos gerar essas duas partições automaticamente, ao mesmo tempo que os dados originais são misturados para garantir o treinamento de todas as possíveis saídas.\n",
    "\n",
    "Após tentativas com diferentes tamanhos de secções do dataset para treino da rede, chegamos ao número 80% como o limite: utilizando mais do que essa quantidade não percebemos melhoria na avaliação da rede durante a fase de testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinamento: \t320\n",
      "Teste: \t\t80\n",
      "Total: \t\t400\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test, target_train, target_test = train_test_split(data, target, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"Treinamento: \\t\" + str(len(target_train)))\n",
    "print(\"Teste: \\t\\t\" + str(len(target_test)))\n",
    "print(\"Total: \\t\\t\" + str(len(faces.target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha da Rede\n",
    "\n",
    "Por se tratar de um problema de classificação de uma dada imagem em uma das 40 possíveis classes de `target`,  instanciamos uma Rede Neural classificadora **Perceptron Multi-Camadas**, composta por uma camada de entrada de 4096 nodos, uma camada intermediária (hidden) de 2048 nodos, e uma camada de saída de 40 nodos.\n",
    "\n",
    "Optamos por utilizar a função de ativação de retificação linear (`relu`, ou Hard Max) por ter demonstrado melhores resultados durante nossos testes, e por ter sido reconhecida como a mais rápida e que obtém melhores resultados em treinamento não guiado de redes neurais aplicadas a imagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=2048, learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(2048), activation='relu')\n",
    "clf.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após ter sido executado o treinamento da rede, utilizamos o pedaço do dataset selecionado para testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_result = clf.predict(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação dos Resultados\n",
    "Para quantificarmos os acertos da rede, utilizamos o seguinte trecho recursivo de código que verifica quantos valores iguais existem nos mesmos índices de dois dados arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matches(arr1, arr2):\n",
    "    try:\n",
    "        return (1 if arr1[0]==arr2[0] else 0) + matches(arr1[1:], arr2[1:])\n",
    "    except IndexError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos, então, a nossa função `match` sobre os resultados recebidos da rede para nossa porção de testes do dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9125\n"
     ]
    }
   ],
   "source": [
    "matchCount = matches(target_result, target_test)\n",
    "print(float(matchCount)/float(len(target_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rede obteve pouco mais de 91% de acertos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
